# ğŸ—‚ï¸ RAG PDF Assistant

A lightweight Retrieval-Augmented Generation (RAG) system that lets you query PDF documents using a local LLM.  
Built with **FastAPI**, **LangChain**, **Ollama**.  
Dockerized for easy deployment.



---

## ğŸš€ Features
- ğŸ“„ Ingest one or multiple PDF files  
- ğŸ” Semantic search with FAISS
- ğŸŒ REST API endpoints with FastAPI  
- ğŸ³ Docker-ready

---

## ğŸ› ï¸ Requirements
- Python 3.10+  
- `pip install -r requirements.txt`
- (Optional) Docker

---

## â–¶ï¸ Usage

### 1. Ingest PDFs

 ```
 python app/ingest.py data/mydoc.pdf
 ```

### 2. Start API

 ```
bash
uvicorn app.api:app --reload
 ```
### 3. Test Endpoints

- Interface â†’ http://127.0.0.1:8000/docs
- Healthcheck â†’ http://127.0.0.1:8000/health
- Query â†’ POST http://127.0.0.1:8000/query with JSON:
- 
 ```
{
  "question": "What does the document say about X?"
}
 ```

## ğŸ³ Run with Docker

Build and run:

docker build -t rag-pdf .
docker run -p 8000:8000 rag-pdf

## ğŸ“Œ Notes

Designed for local, offline RAG â€” no API keys required.